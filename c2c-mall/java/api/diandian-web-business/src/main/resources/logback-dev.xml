<?xml version="1.0" encoding="UTF-8"?>
<configuration debug="true">

    <property name="PRO_NAME" value="diandian"/>
    <property name="LOG_CONTEXT_NAME" value="diandian-web-business"/>
    <!--定义公有变量 日志文件的存储地址 勿在 LogBack 的配置中使用相对路径 -->
    <property name="LOG_HOME" value="log/${LOG_CONTEXT_NAME}"/>
    <!-- 定义日志上下文的名称 -->
    <contextName>${LOG_CONTEXT_NAME}</contextName>
    <!-- 控制台输出 -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 -->
            <pattern>%date %level [%thread] %logger{36} [%file :%line] %msg%n</pattern>
            <!--<pattern>%date %highlight(%level) %green([%thread]) %logger{36} [%file :%line] %msg%n</pattern>-->
        </encoder>
    </appender>
    <!-- 按照每天生成日志文件 -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!--日志文件输出的文件名 -->
            <FileNamePattern>
                ${LOG_HOME}/${LOG_CONTEXT_NAME}.%d{yyyy-MM-dd}-%i.log
            </FileNamePattern>
            <!--日志文件保留天数 -->
            <MaxHistory>90</MaxHistory>
            <!--日志文件最大的大小 -->
            <TimeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>100MB</MaxFileSize>
            </TimeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 -->
            <pattern>%date %level [%thread] %logger{36} [%file :%line] %msg%n</pattern>
        </encoder>
    </appender>
    <!-- kafka appender -->
<!--    <appender name="kafkaAppender" class="com.tigo.tapm.client.logback.KafkaAppender">-->
<!--        <encoder class="com.tigo.tapm.client.logback.KafkaLayoutEncoder">-->
<!--            <layout class="ch.qos.logback.classic.PatternLayout">-->
<!--                <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS};${PRO_NAME};${LOG_CONTEXT_NAME};HOSTNAME;%thread;%-5level;%logger{96};%line;%msg%n</pattern>-->
<!--            </layout>-->
<!--        </encoder>-->
<!--        <topic>app-log</topic>-->
<!--        <proName>${PRO_NAME}</proName>-->
<!--        <zkServers>127.0.0.1:2181</zkServers>-->
<!--        <mail>63976799@qq.com</mail>-->
<!--        <keyBuilder class="com.tigo.tapm.client.logback.builder.AppHostKeyBuilder" />-->
<!--        <config>bootstrap.servers=192.168.100.183:9092</config>-->
<!--        <config>acks=0</config>-->
<!--        <config>linger.ms=3000</config>-->
<!--        <config>max.block.ms=5000</config>-->
<!--    </appender>-->
    <!--myibatis log configure -->
    <logger name="com.apache.ibatis" level="TRACE"/>
    <logger name="java.sql.Connection" level="DEBUG"/>
    <logger name="java.sql.Statement" level="DEBUG"/>
    <logger name="java.sql.PreparedStatement" level="DEBUG"/>
    <logger name="com.diandian.dubbo" level="INFO"/>
    <!--<logger name="org.springframework.integration" level="DEBUG" />-->

    <!-- 日志输出级别 -->
    <root level="INFO">
        <appender-ref ref="STDOUT"/>
        <appender-ref ref="FILE"/>
        <!--<appender-ref ref="kafkaAppender" />-->
    </root>
</configuration>
